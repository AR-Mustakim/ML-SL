{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P3_TwitterSentimentAnalysisMalayLanguage_FeatureExtraction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1kKtfxy8o0gAUOAL3lVvd1gCij5HT5ve_",
      "authorship_tag": "ABX9TyML9Jf4AR/BwtNxHvxwzYTg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hungryphobic/NLP-projects/blob/main/P3_TwitterSentimentAnalysisMalayLanguage_FeatureExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDzdJuvbCVTv"
      },
      "source": [
        "# **Feature Extraction**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELQNr-OTCgFk"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "This phase is we take the cleaned dataset and performed feature extraction so that it can be use for classificaion task later on. Feature extraction which also known as vectorization; vectorization the general process of turning a collection of text documents into numerical feature vectors. Because it prepare the data in such it can be use; as sequence of symbols cannot be fed directly to the algorithms themselves as most of them expect numerical feature vectors with a fixed size rather than the raw text documents with variable length.\n",
        "\n",
        "After some digging, there is some common vectorization method, technique wehich is bag if Word(BOW),count vectorizer and tfidf vectorizer. in this project I will compare the performance of count vectorizer and tfidf vectorizer; and mainly focus on tfidf as from my reading, **The hypothesis** is that tfidf vectorizer is better in term of performance and classification task later on. So,let's find out!\n",
        "\n",
        "\n",
        "For this part of project i will use scikit library. As scikit-learn provides utilities for the most common ways to extract numerical features from text content, namely:\n",
        "\n",
        "> * **tokenizing** strings and giving an integer id for each possible token, for instance by using white-spaces and punctuation as token separators.\n",
        "* **counting** the occurrences of tokens in each document.\n",
        "* **normalizing** and weighting with diminishing importance tokens that occur in the majority of samples / documents.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB1MvXesMB0t"
      },
      "source": [
        "# Import library package and module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwCpOA8haFv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a116a8f-a816-4797-e746-24627a673574"
      },
      "source": [
        "#import module and package\n",
        "%%time\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 332 ms, sys: 162 ms, total: 494 ms\n",
            "Wall time: 719 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUT6YwvcNkvN"
      },
      "source": [
        "# just to try the vectorizer\n",
        "texts = [\"good movie\",\"not a good movie\",\"did not like\",\"i like it\",\"good one\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WARbd1KTUoAm"
      },
      "source": [
        "## **Pre-V**\n",
        "\n",
        "Just do simple vectorization for simple text data just to do an overview of both vectorizer\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBhPCUM6N6sW"
      },
      "source": [
        "### **Count vectorizer**\n",
        "---\n",
        "> CountVectorizer implements both tokenization and occurrence counting in a single class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qooIBMNPWS1"
      },
      "source": [
        "#### Initilize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTJfjewSN5_w"
      },
      "source": [
        "cV = CountVectorizer(ngram_range=(1, 2),min_df=2) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcRmWBIJPl2O"
      },
      "source": [
        "#### vectorize our corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elJKP9BwN07s"
      },
      "source": [
        "x = cV.fit_transform(texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC1xqrHIPvY-"
      },
      "source": [
        "#### View or vectorized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhoiC5gsOdaR",
        "outputId": "a2eeec53-c3d2-453b-c621-f94014fedee2"
      },
      "source": [
        "print(x.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1 0 1 0]\n",
            " [1 1 0 1 1]\n",
            " [0 0 1 0 1]\n",
            " [0 0 1 0 0]\n",
            " [1 0 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "qSSt02LIOecQ",
        "outputId": "64df20fc-6641-468f-cf31-a2fe53a1eff8"
      },
      "source": [
        "pd.DataFrame(x.todense(), columns=cV.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good</th>\n",
              "      <th>good movie</th>\n",
              "      <th>like</th>\n",
              "      <th>movie</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   good  good movie  like  movie  not\n",
              "0     1           1     0      1    0\n",
              "1     1           1     0      1    1\n",
              "2     0           0     1      0    1\n",
              "3     0           0     1      0    0\n",
              "4     1           0     0      0    0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfZYQTwEP0TI"
      },
      "source": [
        "### Tf idf Vectorizer\n",
        "---\n",
        "> **Tf** means ***term-frequency*** while **tf–idf**   means term-frequency times ***inverse document-frequency***: \n",
        "\n",
        "> `tf-idf(t,d) = tf(t,d) x idf(t)`\n",
        "\n",
        "In a large text corpus, some words will be very present (e.g. “the”, “a”, “is” in English) hence carrying very little meaningful information about the actual contents of the document. If we were to feed the direct count data directly to a classifier those very frequent terms would shadow the frequencies of rarer yet more interesting terms.\n",
        "\n",
        ">In order to re-weight the count features into floating point values suitable for usage by a classifier it is very common to use the **tf–idf transform**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcWDphqdP370"
      },
      "source": [
        "#### Initialize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8eZ7LybRpgJ"
      },
      "source": [
        "tV = TfidfVectorizer(min_df=2, ngram_range=(1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1d56Fi2P4dI"
      },
      "source": [
        "#### Vectorize our Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGyC2io5Rp7v"
      },
      "source": [
        "y = tV.fit_transform(texts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vC5edDykP4md"
      },
      "source": [
        "#### View our vectorized data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXE8cTJIRqqn",
        "outputId": "ab505643-5988-435a-c32d-4ba6ffaa81f9"
      },
      "source": [
        "print(y.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.50620441 0.60981846 0.         0.60981846 0.        ]\n",
            " [0.43218341 0.52064623 0.         0.52064623 0.52064623]\n",
            " [0.         0.         0.70710678 0.         0.70710678]\n",
            " [0.         0.         1.         0.         0.        ]\n",
            " [1.         0.         0.         0.         0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "ccQLOvShPEly",
        "outputId": "e8c3ec5f-baa4-4f70-cda7-915927498f77"
      },
      "source": [
        "pd.DataFrame(y.todense(), columns=tV.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good</th>\n",
              "      <th>good movie</th>\n",
              "      <th>like</th>\n",
              "      <th>movie</th>\n",
              "      <th>not</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.506204</td>\n",
              "      <td>0.609818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.609818</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.432183</td>\n",
              "      <td>0.520646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520646</td>\n",
              "      <td>0.520646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.707107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       good  good movie      like     movie       not\n",
              "0  0.506204    0.609818  0.000000  0.609818  0.000000\n",
              "1  0.432183    0.520646  0.000000  0.520646  0.520646\n",
              "2  0.000000    0.000000  0.707107  0.000000  0.707107\n",
              "3  0.000000    0.000000  1.000000  0.000000  0.000000\n",
              "4  1.000000    0.000000  0.000000  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orijj3KZVYiz"
      },
      "source": [
        "## Vectorization\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmvH8zZKxUX7"
      },
      "source": [
        "### V-1)Tf-idf \n",
        "  multipleFileTfidfVectorizer(min_file,max_file,Vectorizer) \n",
        "---\n",
        "1. step1: load cleaned data(contain nan value) --> data_i\n",
        "2. step2: remove nan value datase\n",
        "3. step 3: saved the non empty cleaned data\n",
        "4. step 4: load again our non empty data and assign..\n",
        "  *  I) data_i_Text \n",
        "  *  II) data_i_Polarity\n",
        "5. step 5: vectorize our text data --> data_i_Vec\n",
        "6. step 6: merge our data <-- data_i_Vec concat data_i_Polarity\n",
        "7. step 7: Export our dataset\n",
        "   \n",
        "* ***fp_1*** is file path to import cleaned datset from cleaned dataset folder (refer step 1)\n",
        "* ***fp_2*** is file path to export nan removed dataset to nanRemove folder. Also th epath where the datset will be import (refer step and step4)\n",
        "* ***fp_3*** is file path to saved our final dataset (refer step 7)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TGZrpTQlyhT"
      },
      "source": [
        "def multipleFileTfidfVectorizer(min_file,max_file, vector):  \n",
        "  fp_1 = '/content/drive/MyDrive/Colab Notebooks/tweets_data/for feature extraction/clean dataset/'\n",
        "  fp_2 = '/content/drive/MyDrive/Colab Notebooks/tweets_data/for feature extraction/clean dataset/nanRemove/'\n",
        "  fp_3 = '/content/drive/MyDrive/Colab Notebooks/tweets_data/for feature extraction/clean dataset/vectorized/tfidf/'\n",
        "  \n",
        "  for i in range(min_file,max_file+1):\n",
        "    #initialized our variable\n",
        "    raw = 'data'+str(i)\n",
        "    fp1 = fp_1+str(i)+'.csv'\n",
        "    fp2 = fp_2+str(i)+'.csv'\n",
        "    fp3 = fp_3+str(i)+'.csv'\n",
        "    #step1\n",
        "    raw = pd.read_csv(fp1)\n",
        "    #step2\n",
        "    data = raw.dropna()\n",
        "    print('========================================')\n",
        "    print('Dataset '+str(i)+' details :')\n",
        "    data.info()\n",
        "    #step3\n",
        "    data.to_csv(fp2, index=False)\n",
        "    #step4\n",
        "    data2 = pd.read_csv(fp2)\n",
        "    data2Text= data2['CD-RE']\n",
        "    data2Text= list(data2Text)\n",
        "    data2Polarity = data2['Polarity']\n",
        "    #step5\n",
        "    data2Vector = vector.fit_transform(data2Text)\n",
        "    #step6\n",
        "    data2Vec = pd.DataFrame(data2Vector.todense(), columns=vector.get_feature_names())\n",
        "      # merge our vectorized text data wuth their labelled data\n",
        "    data2ToProcess = pd.concat([data2Vec, data2Polarity], axis=1, ignore_index=False)\n",
        "    #step7\n",
        "    data2ToProcess.to_csv(fp3, index=False)\n",
        "    # %%time\n",
        "    print('Dataset '+str(i)+' finished successfully!!')\n",
        "    print('========================================')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCnV-01UlymO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "773d4453-4621-4421-83f3-4b653db9fbdc"
      },
      "source": [
        "%%time\n",
        "tfidf= TfidfVectorizer(min_df=2, ngram_range=(1,2))\n",
        "multipleFileTfidfVectorizer(19,19,tfidf)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================\n",
            "Dataset 19 details :\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 683 entries, 0 to 791\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   CD-RE     683 non-null    object \n",
            " 1   Polarity  683 non-null    float64\n",
            "dtypes: float64(1), object(1)\n",
            "memory usage: 16.0+ KB\n",
            "Dataset 19 finished successfully!!\n",
            "========================================\n",
            "CPU times: user 841 ms, sys: 96.2 ms, total: 937 ms\n",
            "Wall time: 2.13 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k30bs0s1cOBd"
      },
      "source": [
        "### V-2)Count Vectorizer\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKGRdGe5lypS"
      },
      "source": [
        "def multipleFileCountVectorizer(min_file,max_file, vector):  \n",
        "  \n",
        "  fp_11 = '/content/drive/MyDrive/Colab Notebooks/tweets_data/for feature extraction/clean dataset/nanRemove/'\n",
        "  fp_12 = '/content/drive/MyDrive/Colab Notebooks/tweets_data/for feature extraction/clean dataset/vectorized/count vectorizer/'\n",
        "  \n",
        "  for i in range(min_file,max_file+1):\n",
        "    #initialized our variable\n",
        "    fp1 = fp_11+str(i)+'.csv'\n",
        "    fp2 = fp_12+str(i)+'.csv'\n",
        "    \n",
        "    #step1\n",
        "    data = pd.read_csv(fp1)\n",
        "    dataText= data['CD-RE']\n",
        "    dataText= list(dataText)\n",
        "    dataPolarity = data['Polarity']\n",
        "    #step2\n",
        "    dataVector = vector.fit_transform(dataText)\n",
        "    #step3\n",
        "    dataVec = pd.DataFrame(dataVector.todense(), columns=vector.get_feature_names())\n",
        "      # merge our vectorized text data wuth their labelled data\n",
        "    dataToProcess = pd.concat([dataVec, dataPolarity], axis=1, ignore_index=False)\n",
        "    #step4\n",
        "    dataToProcess.to_csv(fp2, index= False)\n",
        "    \n",
        "    print('Dataset '+str(i)+' finished successfully!!')\n",
        "    print('========================================')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnIw9-JDlytS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38aca3f-38a3-43a1-ef9c-fa46ecae7fea"
      },
      "source": [
        "%%time\n",
        "countVectorizer = CountVectorizer(ngram_range=(1, 2),min_df=2) \n",
        "multipleFileCountVectorizer(19,19,countVectorizer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset 19 finished successfully!!\n",
            "========================================\n",
            "CPU times: user 170 ms, sys: 2.15 ms, total: 172 ms\n",
            "Wall time: 387 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}